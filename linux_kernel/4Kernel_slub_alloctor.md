# 内核内存分配器
> 源码将以 2.6.24 版本来讲解，slub 分配器从 2.6.22 版本开始引入

内核按页来管理内存，但是内核在运行期间还需要小于整页的小内存，所以 Linux 内核通过对 solaris 开发 Slab 分配器进行优化，开发了3种小内存分配器，分别是 slab、slub、slob 分配器。slob 分配器主要用于移动平台，其特点是分配器本身使用内存很少；slab 是最初的非移动平台的分配器，但是由于对 NUMA 的支持不好，所以又开发了现在主流的 slub 分配器。

## 分配器原理

1. 分配器简介

内存分配器的本质其实就是对小对象的缓存，一个运行的程序会不断获取一段内存用于存放某个对象的数据，使用完毕后归还这段内存。获取内存时有昂贵的成本，所以可以将这些小对象缓存起来，获取时先查看缓存中是否有可用对象，如果有就直接取出直接使用，否则获取一大块内存（比如内核中的页分配器、用户空间的内存映射）初始化成小对象，满足当前请求后，剩余的缓存起来；对象使用完毕，先缓存起来，如果缓存中小对象过多，才把整块未使用的内存归还。所以分配器形如如下示意图：

```

obj_list_head[sizes]
        ......
        +----+
 8byte  |next|--->[obj_ptr]--->[obj_ptr]--->[obj_ptr]
        +----+
 16byte |next|--->[obj_ptr]--->[obj_ptr]--->[obj_ptr]
        +----+
 32byte |next|--->[obj_ptr]--->[obj_ptr]--->[obj_ptr]
        +----+
 64byte |next|--->[obj_ptr]--->[obj_ptr]--->[obj_ptr]
        +----+
        ......
```

内核的各种类型的内存分配器的核心几乎都是上面示意图给出的模式，一个按 `2^n` 字节分组的缓存（链表）数组，其中使用链表串联了一些相应大小的对象首地址，当我们使用 `2^n` 大小的内存就从 `n` 下标的链表中取出一个，使用完再归还到相应的链表中。上面这个简单的模式看上去更像一个对象缓存池，因为分配出来的内存丢失了大小信息，所以在使用的过程中必须带上链表头信息，归还时才能正确的归还；另一方面，简单的分配一大块内存再分割成小块对象链接到链表，又丢失了对象内存的来源信息，使得如果来自底层的整块内存的所有对象都空闲时不能被回收掉。所有类 `slab` 分配器的核心都是围绕这两点来设计的，掌握了这两点的处理就掌握了这类分配器的算法核心。

2. 分配器与页描述符

只要涉及到虚地址转换就离不开页描述符，同样在设计内存分配器时，通过虚地址得到页描述符，并在页描述符中存储关于分配器的信息，上面提出的问题都可以迎刃而解。页描述符中的分配器信息如下：

```c
struct page {
    ...
    union {
        ...
        unsigned int inuse; /* 当前 slab 中非空闲的对象数 */
    };
    union {
        ...
        struct kmem_cache *slab; /*虚地址所属的分配器描述符*/
    };
    union {
		void *freelist;		/* 空闲列表对象 SLUB*/
	};
    struct list_head lru;
    ...
};
```

上面我们已经提过，先分配大块内存然后分割成小对象缓存起来，就是核心思路。这里的大内存当然是来自伙伴系统的以页为单位的单页或连续页，如果这些页被用于类 `slab` 分配器，则通过 `PG_slab` 标志标识。那么通过如下代码片段就可以得到分配器描述符：

```c
static struct kmem_cache *virt_to_cache_descriptor(const void* vaddr)
{
    struct page *pg = virt_to_page(vaddr);
    /*分配器中的连续页都是组合页*/ 
    pg = compound_head(pg);
    if (pg->flags & PG_slab)
        return pg->slab;
    return NULL;
}
```

有了上面的转换就可以在使用内存时，不必带上其他的额外信息了。上面提到的第二点问题，也是通过页描述符解决的，软件设计模式上有个万金油，就是任何看似复杂的、不能解决的问题，只要套入一个中间层就可以完美解决，内核在很多地方都引入一个中间层来解决问题。如果我们把缓存链表设置在 `kmem_cache` 上，即使在页描述符上引入一个计数器来记录大块内存区域中空闲对象的数目，但是由于空闲的对象都被混和的链接在同一个链表上，无法快速的分离，所以还是不能做到缓存过多内存时回收空闲内存块。所以引入一个中间链表，来自各种页的对象链接在同一个链表上，然后再将这个链表作为一个元素链接在 `kmem_cache` 上就可以很好解决这个问题了。自然而然，这个中间层链表在该块内存首页的页描述符上 `freelist` 字段，然后通过 `page.lru` 链接到 `kmem_cache` 中既可。我们将上面的示意图优化后如下：

```

kmem_cache[size]
    +------+
    | next |--->[page.lru]--------->[page.lru]
    +------+    [page.freelist]     [page.freelist]
                     |                   |
                     |               [obj_ptr]--->[obj_ptr]--->[obj_ptr]
                     |
                 [obj_ptr]--->[obj_ptr]--->[obj_ptr]

```

当 `page` 中的所有对象都空闲，就可以直接剥离 `page.lru` 然后释放该 `page` 到伙伴系统既可。

## 分配器的抽象

有了上面的知识，我们就可以开始列出分配器的相关数据结构，并讲解其初始化的过程了，我们仅列出主核心的字段，数据结构如下：

```c
struct kmem_cache_node {
	unsigned long nr_partial; /*partial 链表中的页数量*/
	atomic_long_t nr_slabs; /*该节点上总的slab数量*/
	struct list_head partial; /*存储部分被使用的slab*/
};

struct kmem_cache_cpu {
	void **freelist; /* per-cpu 缓存中的对象头指针 */
	struct page *page; /*当前装载的 slab 的页描述符*/
	int node; /*当前 slab 的内存来自的节点*/
    ...
};

struct kmem_cache {
	int size; /* 该分配器对象的占用的实际内存大小 */
    ...
	int order; /*当补充该分配器内存时，分配的页数 2^order */

	struct kmem_cache_node local_node;/*本地节点的缓存*/
    ... 
	struct list_head list;	/* 为了所有分配器，会将他们串联起来 */
	int defrag_ratio;
    /*为了支持NUMA，每个节点都有一个该对象的slab对象集合*/
	struct kmem_cache_node *node[MAX_NUMNODES];
    /*为了减少分配时的竞争成本，构建在分配器上的 per-cpu 缓存*/
    struct kmem_cache_cpu *cpu_slab[NR_CPUS];
    ...
};
```

我们先忽略 Per-CPU 的缓存概念，这样可以更好的把握实质，上面已经说过 `page` 中的就是最终缓存的入口，我们也把用于分配小像的页描述符称为 `slab 对象`，这个几个对象的关系如下：

```

kmem_cache[x]

                    +-----------+  partial  +---------+  page.lru +---------+
                    |cache_node1|---------->|slab_page|---------->|slab_page|
  +----------+      +-----------+           +---------+           +----+----+
  |  node[]  |----->|cache_node2|                                      |page.freelist
  +----------+      +-----------+                                      v
  |   ...    |                                                     [obj_ptr]-->[obj_ptr] list_A
  +----------+      +-----------+     +---------+
  |cpu_slab[]|----->|cache_cpu1 |---->|slab_page|
  +----------+      +-----------+     +---------+
                    |cache_cpu2 |     |freelist |
                    +-----------+     +----+----+
                                           |
                                           v
                                       [obj_ptr]-->[obj_ptr]-->[obj_ptr] list_B
```

注意 `list_A`（`page.freelist`） 和 `list_B` （`kmem_cache_cpu.freelist`）可能存储的同源的对象指针，但是是不同的东西。后面讲解  `per-cpu` 缓存时会再细讲。

## 分配器初始化

在知道分配器的各个部件的布局后，现在开始初始化。内核在 `start_kernel()` 后期初始化 `slab` 分配器，由于它依赖伙伴系统页分配器，所以很明显需要在伙伴系统初始化完毕后初始化，入口函数为 `kmem_cache_init()`。因为小于一页大小的内存都使用 `slab` 分配器分配，所以内核预定义了 12 个 `kmem_cache` 对象，通过 `2^n` 这样的关系就可以为分配大小快速定位分配器，这些分配器的槽位下标为 `3~11`，剩余的 `0~2` 作为特殊大小的分配器，特别是 `0` 号分配器，它被 `slab` 分配器内部使用，用作 `kmem_cache_node` 的分配。在初始化使用状态机来记录初始化的进度，因为分配器的初始化又依赖分配器来分配内存，这就产生了 `鸡蛋` 问题。

